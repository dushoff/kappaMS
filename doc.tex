\section{Introduction}
%Copied from main.tex on Overleaf

Real outbreaks have significant heterogeneity in secondary case distributions -- including ``superspreading,'' marked by a small fraction of individuals causing a disproportionately large fraction of realized transmission \cite{lloydsmith2005superspreading, woolhouse1997heterogeneities}.
Several distinct factors influence who becomes a superspreader and can disproportionately affect outbreak dynamics \cite{kuylen2022different,wallace2025hotspot}.
 Superspreading can help explain why epidemics break- and burn out in some times and places but not others, despite apparently similar contexts. 
%Furthermore, when control efforts can successfully target individuals, groups, or settings for which atypically high transmission is more likely, they may be especially effective
Furthermore, control efforts that incorporate superspreading into their design may be more effective \cite{garske2008effect, nielsen2023counterintuitive, sneppen2021overdispersion}. 
%When prevalence is low and stochasticity is pronounced, superspreading can determine the fate of an outbreak\cite{matthews2005new,althouse2020superspreading}.
Superspreading may be most salient for disease dynamics and control strategies at the time of outbreak \cite{goyal2022multiscale}. % see if this is actually the reference we want here
For this reason, theoretical treatment of superspreading emphasizes individual-level transmission patterns, often while assuming a fully susceptible population.~%possible citation but I'm not in love with it: Elie et al. 2022 Proc B
Over longer timescales, the processes of susceptible depletion and resupply, which are elegantly captured in mechanistic compartmental models, drive population-scale disease dynamics. Despite shared theory motivating models that highlight individual-level transmission events and superspreading, and those that highlight population-level transmission dynamics, there remains a gap between how each model framework treats individual-level transmission heterogeneity. 

Theoretical treatment of superspreading has focused on effective, non-mechanistic models that link observed secondary case counts to a continuous random variable, the ``individual reproduction number,'' via a Poisson sampling process\cite{lloydsmith2005superspreading}.
% Canonically, the individual reproduction number is modeled as a gamma distribution, giving rise to negative binomial secondary case distributions.
 In this way, variation from the stochastic process of successful transmission is conceptually separated from a more intrinsic individual-level heterogeneity [in expected infectiousness] that may emerge from a plethora of potential differences in physiology, contact patterns, or behaviors between individuals.

In its simplest form, the canonical ODE S[E]IR model assumes homogeneous rates of recovery and constant, uniform infectivity across all individuals during the infectious stage \cite{Hethcote2000, Kermack1927}. Although single-infective-class compartmental models would seem ill-equipped to describe heterogeneity, even the SIR model yields exponentially distributed recovery times and thus, when linearized, geometric secondary case distributions. Further, taking susceptible depletion into account, the exponentially-distributed durations still drive variation in the number of infections attributable to fractions of the population infected at a given time, while a changing effective reproduction number drives variation between fractions of the population infected at different times. In other words, even fully deterministic ODE models predict variation around \Ro~in the expected number of cases per case.
We term this variation, ``emergent heterogeneity.''
In practice, epidemiological modelers also include \emph{explicit heterogeneity} into their models, for example by considering age- or spatially-explicit compartments that may have different expected rates of mixing, transmission, or recovery \cite{schenzle1984agestructured}.
Explicit heterogeneity reproduces superspreading in linear compartmental models \cite{meehan2023replicating}.


 We delineate the distinct sources of individual variation in transmission inscribed into a simple SIR model. We trace how these sources compose into observed or observable heterogeneity in different settings, for example contrasting how heterogeneity emerges in dynamical models versus linearized, or branching-process models. Throughout, we highlight the understudied but critically important role of disease dynamics \textit{per se} in generating individual-level heterogeneity. 
We aim to spur the development of theory and methods that better integrate heterogeneity and dynamics, ultimately facilitating feedback between data on incidence and individual-level transmission chains, mechanistic model specification, identification, and validation, and intervention design.

\section{Box: Kappa tutorial}
\begin{framed}
	\noindent\textbf{Box 1. $\kappa$ tutorial.} 
%Adapted from main.tex on Overleaf	

For a continuous distribution with mean $\mu$ and variance $\sigma^2,$ the (generalized)
\emph{dispersion parameter}, $\kappa$, is defined as the squared coefficient of variation $\sigma^2/\mu^2$. 
The dispersion parameter of a discrete distribution  with mean $\mu$ and variance $\sigma^2$ is defined as
$\kappa_\mathrm{discrete} = (\sigma^2-\mu)/\mu^2$.

The statistics $\kappa$ and $\kappa_\mathrm{discrete}$ have desirable properties for a dispersion measure: They \emph{increase} with dispersion around the mean and equal zero for a Dirac delta function. 

The dispersion parameter is \emph{invariant} under Poisson mixing.
When a gamma distribution is parameterized by its mean $\mu$ and dispersion $\kappa$, the resulting negative binomial distribution, derived from  Poisson mixing, is likewise parameterized by $\mu$ and $\kappa_\mathrm{discrete} = \kappa$.
The connection between $\kappa$ and $\kappa_\mathrm{discrete}$ holds for Poisson mixture with any mixing distribution. 
%Thus, we can use $\kappa$ statistics to compare models with different mean-variance structures.

In our setting, the continuous distribution corresponds to the expected transmission rate, and the discrete distribution arises from the stochastic realization of that rate, i.e., by compounding a Poisson distribution with a rate parameter derived from the continuous distribution. 
Hence, $\kappa$ and $\kappa_\mathrm{discrete}$ can be used to characterize the dispersion of secondary case distributions.


\end{framed}
\section{Results}
Demographic stochasticity can generate ``emergent'' heterogeneity even in the absence of explicit differences between individual-based rates (\Fref{ls}). In simple models, this heterogeneity can be characterized. We explicate the notion that this is predictable (see Box). \jd{Is that really what Box is doing, though? Or more about linking the emergent stochasticity in the deterministic vs.\ demographic-stochastic models?}

\begin{figure}
\centering
\includegraphics{lsFig.Rout.pdf}
\caption{
	\textbf{Heterogeneity emerges even from a simple, linearized compartmental model} due to implicit variation in recovery times among infectors. (left) Activity distributions (density curves) and secondary case distributions (density histograms) for the outset of an SIR epidemic. Because the first bin (at zero) sits at the boundary of support for each distribution, we have plotted this bin as double the density and half the width; this adjustment preserves area-to-area correspondence with the PDF, while facilitating visual comparison of the heights of the density and mass functions. (right) Inequality curves for \emph{activity} distributions from SIR models with differing \Ro~are identical (and indistinguishable due to overplotting); inequality in the \emph{case} distribution decreases with \Ro~towards the theoretical limit of the activity distribution.
}\flab{ls}
\end{figure}
The inequality in the secondary cases, i.e., the relationship between the fraction of new infections and the fraction of infectors, varied by \Ro; the inequality in the activity distribution did not.
The share of Poisson noise in the inequality shrank in epidemics with large \Ro (\Fref{ls}, right panel).

The left panel of \Fref{ls} shows patterns of emergent heterogeneity in secondary case numbers during the early stage of an outbreak, when the population is fully susceptible.
Both activity distribution and secondary case distribution depend on \Ro.
How would the secondary distribution look if we examined all infectors over the entire outbreak?
To address this, we simulated epidemic outbreaks with different \Ro~values in a population of $10000$.
For each infected individual, we recorded the number of secondary cases they generated during the outbreak. 
The top row of \Fref{RcAverage} shows realized distributions of ``offspring cases'' caused by individual infectors in simple, stochastic SIR epidemics. Unlike in the linearized case above, the distributions remain indistinguishable across a wide range of the key parameter \Ro.
This seems surprising: in particular, we see much greater dynamical changes when \Ro~ is large; we might expect this to be reflected in a larger variation in the offspring distribution.
 
To reconcile these two observations, we examined how heterogeneity differs when analyzing epidemiologically relevant cohorts, which are groups of individuals infected at the same time, as the outbreak unfolds.
A large \Ro~results in a large initial number of cases per case; however, rapid depletion of susceptible individuals reduces the chance of large secondary cases.
In contrast, a small \Ro~produces fewer initial cases per case, but the slower susceptible exhaustion allows for larger secondary cases (\Fref{Cohort}).
We then split the total case-per-case variance over the course of the outbreak into between- and within-cohort components. We found that epidemics with larger \Ro\ have larger between-cohort variation, as expected. However, this is balanced by smaller within-cohort variation (\Fref{RcAverage}, lower panel). 
We can in fact prove that the variance in case-per-case, conditioned on the entire outbreak, is equal to one, regardless of the value of \Ro~(Section \ref{sec_proof}).
\begin{figure}
\centering
\includegraphics{RcAverage.Rout.pdf}
\caption{
\textbf{Indistinguishable empirical distributions of case-per-case for epidemics of different strengths conditioned over the entire outbreak cycle.}
	Epidemic outbreaks have been simulated for a population of $10000$ with different \Ro\, and the number of secondary cases per infector has been recorded at the time of outbreak extinction (top panels).
	Identical variance in case-per-case for epidemics of different strengths modeled using simple compartmental models (lower panel).
	As \Ro~increases, between-cohort variance rises, and within-cohort variance falls, maintaining constant total variance of one.
}\flab{RcAverage}
\end{figure}


We are also interested in what emergent distributions will look like to people studying outbreaks in real time. We are interested, at least to some extent, both in how cohorts change through time, and in what the outbreak will ``look like'' if we observe from a particular time.  
To do so, we simulated a deterministic SIR model and stopped it at different cutoff points.
At each time point, we calculated case-per-case heterogeneity based on the cases generated up to that time by infected cohorts.
We found that in the early stage of the outbreak, the observed heterogeneity was lower than that observed in the linearized model or throughout the entire outbreak, and that it varied by \Ro~(\fref{Naive}). 
By the end of the outbreak, the heterogeneity in case-per-case for different values of \Ro~became indistinguishable and equal to one.

We also examined an idealized scenario in which, for each time point, we computed case-per-case heterogeneity over the entire outbreak, considering all cohorts that had become infectious up to that time.
In epidemics with lower \Ro, the case-per-case mean and variance across early-infected cohorts were the same as those in a linearized model (\fref{timeCutoff}).
Incorporating cohorts who later, but prior to the outbreak peak, became infected reduced variability. Further incorporating those cohorts that became infected after the peak increased the variability.
By the end of the outbreak, all epidemics with different \Ro~agreed on the case-per-case heterogeneity, measured by $\kappa$.


\begin{figure}[h!]
	\centering
	\includegraphics{kappa/PlotTrunc.Rout.pdf}
	\caption{
		\textbf{Distribution of case-per-case evolves over the course of outbreak.}
		Panel a: The size of the cohort infected at each rescaled time point is measured by incidence at that point.
		Panel b: The mean and standard deviation of case-per-case at each time are computed using the realized cases up to that point. 
		%Early in the outbreak, the variability in case-per-case is yet to be fully revealed, as those still infectious generated the same number of secondary cases as those who had just recovered.
		After the peak, the standard deviation has already settled at one; the mean approaches one rapidly, regardless of \Ro.
		Panel c: The squared coefficient of variation of case-per-case $\kappa$ climbs over the course of the outbreak.
		Epidemics with small \Ro~take longer to reach their peak. Even early on, differences in how long people remain infectious in the same cohort become important, making the within component of $\kappa$ larger (and, as a result, decreasing the between component part). 
		In epidemics with large \Ro, as opposed to those with \Ro~close to one, the between-cohort component jumps after the outbreak peak as the susceptible pool depletes.
		For panels b and c, the simulation was stopped at each time point to compute the y-axis value. 
		The y-axis value at each time point was computed by assigning to each cohort the number of realized cases up to that time.
		In all panels, time units measured in the mean infectious period are again scaled relative to the peak time.
	}\flab{Naive}
\end{figure}

%It's also possible to imagine realistic approaches between these two extremes, but let's put that off for later. There are methods (including by Dushoff and Park) for thinking about this at the cohort level, but not with a focus on individual variation. Maybe this is just for discussion. OR maybe we should also look at plots where we go up until a particular time and only count recovered infectors.
%\ag{Does \fref{timeCutoffV1} do what we are looking for?}

\begin{figure}[h!]
	\centering
	\includegraphics{kappa/RcTimePlotVaryingPeak.Rout.pdf}
	\caption{
		\textbf{Nowcasting the case-per-case distribution evolves as the outbreak unfolds.}
		Panel a: Incidence represents the size of each cohort infected at each rescaled time point.
		By ``rescaled,'' we mean that time has first been scaled by the mean infectious period and is then measured relative to the outbreak peak.
		Panel b: At each time, the mean and standard deviation of cases caused by each case are calculated using only cohorts infected up to that time.
		The mean cases per case is larger in early-infected cohorts and depends on the key parameter \Ro. 
		As time goes by, later-infected cohorts have larger weights, as measured by incidence. These cohorts experience susceptible pool depletion, leading to fewer secondary cases and a lower mean case-per-case number. 
		After the peak, the susceptible population size stabilizes, and the mean and variance approach one. 
		Panel c: The between-cohort component of the squared coefficient of variation $\kappa_{bet}$ is negligible among the early-infected cohorts, as they experience a similar size of susceptibles. As the outbreak unfolds, the decline in the susceptible population drives between-cohort variation, which is more pronounced in epidemics with large \Ro. The squared coefficient of variation $\kappa$ reaches its minimum around the outbreak peak; the largest cohort, measured by incidence, experiences a sharp depletion of susceptibles, and the impact of variation in recovery time fadesâ€”declining the variance and, in turn, $\kappa$. After the peak, $\kappa$ rebounds to one. 
		For panels b and c, the y-axis value at each time point was computed using only the cohorts that had been infected up to that time.
	}\flab{timeCutoff}
\end{figure}



%\begin{figure}
%	\centering
%	\includegraphics{kappa/RcTimePlotVaryingPeakObs.Rout.pdf}
%	\caption{
%		\textbf{The expected number of secondary cases generated by each case evolves over the course of the outbreak.}
%		Panels (a-c) correspond to incidence, the mean and standard deviation of the number of cases per case,  and its squared coefficient of variation, respectively, as in \fref{timeCutoff}.
%		For panels b and c, the simulation was stopped at each time point to compute the y-axis value. 
%		The y-axis value at each time point was computed by taking into account the recovered individuals by that time.
%		More specifically, the contribution of each cohort to the overall mean and variance was weighted by the fraction of recovered individuals in the cohort.
%	}\flab{timeCutoffV1}
%\end{figure}

%\tg{Can we make a note about for epidemics with large R0, if you don't start tracking cases right from the beginning, you'll already underestimate cases/case }
%\jd{Yes, this should go into the paper.}

\section{Discussion}

In SIR-type epidemics, the effective reproduction number declines as the susceptible population becomes depleted. Consequently, if surveillance begins after the initial transmission generations, estimates of cases-per-case will represent the reduced effective reproduction number rather than \Ro \cite{pellis}. As a result, delayed surveillance may yield substantially lower estimates, especially when \Ro is large, due to rapid depletion of the susceptible pool.

% Although there have been efforts to both quantitatively describe individual-level heterogeneity in contact rates \cite{woolhouse1997heterogeneities} and to parameterize biologically realistic secondary case distributions, abstracted from the mechanism \cite{lloydsmith2005superspreading}, these efforts have been largely separate from the construction and evaluation of the compartmental models that enable epidemic forecasting and intervention design (but see \cite{meehan2023replicating}). Here, we expand [or some other verb] the bridge between individual- and population perspectives of disease spread. By integrating the study of superspreading, and the dynamical consequences of structured populations and susceptible depletion, we facilitate [x,y,z]
% x, y, z might consist of dynamical consideration of superspreading, outbreak characteristics of compartmental models, opportunity for model identifyability or validation with secondary case data, etc.


%, b) rigorously contrast emergent heterogeneity from compartmental models and the observed heterogeneity secondary case distributions from stochastic realizations of those models (potentially simulated with added realism, such as heterogeneous mixing) or c) simultaneously validate models with observed incidence *and* secondary case distribution. In this manuscript, we first describe statistics for quantifying the emergent heterogeneity, then provide some general rules for how the topology of compartmental models affects the degree of emergent heterogeneity. Next, we consider how different time frames dictate different views of emergent heterogeneity, and how secondary case distributions evolve through time in different model scenarios. Finally, we compare the emergent heterogeneity from ODE compartmental models to the dispersion in secondary case distributions generated in simulations of the systems the models describe. 

% ... Similar to how reproduction numbers ($R_\mathrm{effective}$ or $R_0$) serve as common currency by which to measure and compare models and epidemics, our contribution invites parallel treatment of variation about those mean quantities.
